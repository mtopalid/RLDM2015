\section{Introduction}

According to \citet{Schneider1977}, a behaviour is automatic
(i.e. becomes an habit) if a sensory events always elicit the same behaviour,
even if the subject is doing something else. Think, for example, of someone
entering a dark room while talking on the phone and switching on the light
without ever really thinking about it. How this behaviour is acquired in the
first place ? How do we learn such habits ? \citet{Seger2011},
characterized habit learning using five definitional features: inflexible,
incremental, unconscious, automatic, and insensitive to reinforcer
devaluation. This tentative definition seems to be clearly in opposition with
decision making that we could think of as flexible and highly sensitive to
reinforcer devaluation. However, there are more and more evidences these two
types of learning are somehow linked together (\citet{Yin2006}), the
question being how ?

In a recent (unpublished) study, monkeys have been tested on a two-armed bandit
task using a pharmacological approach, combining both decision making and
procedural learning. More precisely, during a trial, two different cues
(shapes) are presented on a screen at random locations. Each cue has been
assigned a fixed reward a priori probability (0.75 and 0.25) and the monkey is
expected to choose the cue with the highest associated reward probability.
After a few trials, monkeys are able to choose the best cue among the two
(performance is optimal). These two cues are called the familiar cues. After
this training stage, two unfamiliar cues with the same probability are
presented during several trials (interleaved with trials using familiar
cues). In one condition, the internal part of the Globus Pallidus (the main
output structure of the BG) is injected with a saline solution (no effect) and
in the other condition, it is injected with muscimol (inactivation). Results
tend to show that performances related to familiar cues stay unchanged,
independently of GPi inactivation, while learning of new cues is deeply
impacted when GPi has been inactivated. This tends to suggest BG might be
critical in learning decision but this learning can be later transferred to the
cortex.




	%% A lot of times during a day, we are asked to make decisions of different kind, important or not. Each of these decisions show who we are, through influencing our behaviour and habits. Nowadays, many scientists are involved in research of understanding the underlying mechanisms of this high-level cognitive function. It is a widely held view that basal ganglia participate in decision making, but with unknown role regarding the formations of habits. How an animal can shift from a known behaviour with expected outcome to a habitual one?

	%% Piron experimented with monkeys on a two-armed bandit task under a pharmacological approach, combining habitual behaviour and procedural learning. In this kind of tasks, the subjects are requested to determine the initial unknown outcome of a choice among different options. During a trial, two different shapes are presented to a screen in front of a monkey. Each shape is interlaced with a reward probability (0.75 and 0.25). Its task is to choose one by pushing a button relevant to the position of the shape. Finish of the movement indicates reward delivery according to chosen shape's probability. Through repetition, the monkey decodes the hidden outcomes and chooses almost each time the shape with the highest one. Then, they interchange between trials with familiar targets of explicit values and new pairs of targets of implicit value. A reflexive behaviour was triggered by the former trials in which the choice was the best option and quick, while the later are associated to an exploratory early phase and a late exploitation phase of a learning process. Yet, they inactivated the internal part of the Globus Pallidus (GPi), the main output structure of the BG with injections of muscimol. They concluded that disruption of BG output resulted to inability of learning new contingencies, while the reflexive choice of known target was slightly slower, but not impaired.

	%% We introduce a computation model that simulates cortex, basal ganglia and thalamus, able to solve the two-armed bandit task, as described above, using reinforcement learning and explicit valuation of outcome (Guthrie et al., 2013). Our results demonstrate that Hebbian learning at cortical level after each move, and not only after reward, is sufficient for the model to choose always the best option. Then, by inhibiting the output nuclei of the model (GPi), we show how learning has been transferred from the basal ganglia to the cortex, simply as a consequence of the statistics of the choice. Our results are consisted with equivalent monkeys' experiments (unpublished data at the time of writing) and suggest that the basal ganglia implicitly teach cortex the values of new options. In the end, it is demonstrated the ability of cortex to solve the task perfectly, even if it exhibits slower reaction times.
