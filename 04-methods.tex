\section{Description of the model}

	The architectural basis of the model has been originally described by \citet{Guthrie2013}. They presented a biophysically based, model of action selection that can solve the two-armed bandit task. Two parallel action selection units compose the model with inputs from distinct areas of cortex: one for solving the cognitive action selection, and the other for the motor. The nuclei included to the model are: Cortex (Cx), Striatum (Str), Subthalamus (STN), Globus pallidus (GPi) and Thalamus (Th). Each module comprises of a closed-loop positive feedback direct pathway (Cx-Str-GPi-Th-Cx) and a closed-loop negative feedback hyperdirect (Cx-STN-GPi-Th-Cx). Furthermore, it consists of one instance of the center-surround architecture of \citet{Mink1996}. The interaction between the two pathways induce action selection at the model. In order a solution of the task to be correct, the decision at  cognitive level must be available for guidance of the decision at the motor. This was implemented at striatal level. A simulated dopamine reward signal forms a type of actor-critic network, which achieves learning in the model.

	The general architectural diagram of the formulation is illustrated in Figure \ref{fig:architecture}. In the original model, inactivation of basal ganglia output results inability of the network to produce a decision. To overcome this problem, connections at cortical level are added. 
	First, self-connections added to cortical nuclei. Each neuron inhibits all the others and excites itself. The idea came from the need for enhancement of the competition between neurons.
	 With lateral competition, a single connection can emerge independently in motor and cognitive cortex. The associative competition  can ensure the selection of the proper couple. To establish this competence, connectivity 	among the different cortical parts was included. In contrast with the previous model the cross talking between the two parallel modules happened only through basal ganglia. Thus, inactivation of GPi automatically meant loss of this ability. 
	Yet,  Guthrie model did not provide time to cognitive cortex for making a decision, before motor  decides the appropriate move. They are a lot of cases that the two decisions are simultaneously, even the motor before the cognitive, at some cases. In order to obtain this difference in timing, except the added connections, a part of the original parameters have changed. 
	
	One of the results from experiments by \citet{Piron2015}, was the success of monkeys to reserve their knowledge after inactivation of GPi. This is a strong indication for storage of information outside of basal ganglia. It's known that striatal learning follows the rules of reinforcement learning. Each time BG computes the expected reward of an action and adjusts the weights according to the error of the real one. In the opposite side is the cortical learning about which our knowledge is limited. We hypothesized that learning occurs after every move without the need of any computation or outcome. Therefore, hebbian learning is a good candidate. The success of this choice is ensured by the participation of BG to the action selection. After few trials, BG learn the best option and guide cortex to choose it. In this way, the number of choice of the cues are capable, through the statistics, to drive cortex to learn properly. This is also confirmed by the absence of GPi, when cortex is incapable to learn new strategies. At that point, choices are statistically random, so the learning is balanced between the two cues. 